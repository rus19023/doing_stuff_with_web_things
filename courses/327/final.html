<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        <link type="text/css" rel="stylesheet" href="https://rus19023.github.io/myportfolio/css/styles.css" />
        <link type="text/css" rel="stylesheet" href="http://127.0.0.1:5501/css/styles.css" />

        <title id="cit327weekpagetitle" class="title">page title</title>
    </head>

    <body>
        <header id="autoheader327" class="title">auto header</header>
        <main class="centered">
            <h1 id="cit327weekpagetitle2" class="padit title">page title</h1>
            <h2 id="paperTitle" class="padit title">paper title</h2>
            <div>
                <h2 class="title">Create and Maintain a Manageable Corporate Data Warehouse</h2>
                <h3 class="title">Introduction</h3>

                <p class="normal-text">
                    This paper is to share concepts I have learned about Big Data Analysis and Warehousing, and the accompanying Technology, Methodology and the available Tools and Techniques.
                    With the massive numbers of available tools, frameworks, libraries, databases, companies and corporations, developers, techniques, data sources and other resources available today, all of which is increasing at rocket speed, managing Big Data is a colossal issue.
                </p>

                <h4 class="title">Big Data</h4>
                    <p class="normal-text">
                        Big Data elements are "extremely large" datasets, including JSON or XML document-based collections or embedded structures of up to 100 nested container levels, spreadsheets, wide columnar tables or relational database tables of millions of rows, or any combination of these types of data sources.
                        <br><br>
                        There are many ways to analyze Big Data using the above-mentioned resources that to filter, summarize, and detect outliers, trends, patterns and cycles. These necessary procedures enable business decisions to be made correctly, due to the varied types of sources that are collected needing to be formatted, summarized and/or normalized through ETL or ELT processes.
                    </p>

                    <p class="normal-text">
                        <figure>
                            <img class="centerimg" src="../../images/Model.jpg" alt="Basic data warehouse model infographic">
                            <figcaption class="source centered">
                                Basic data warehouse model infographic provided by Instructor
                            </figcaption>
                        </figure>
                    </p>

                    <p class="normal-text">
                        The National Institute of Standards and Technology issued a report defining Big Data as “extensive datasets—primarily in the characteristics of volume, velocity, and/or variability—that require a scalable architecture for efficient storage, manipulation, and analysis.” <a href="#bigdata">[source]</a>
                        <br><br>
                        Big Data has also been defined as an amount of data that exceeds a petabyte, which is a million gigabytes.
                    </p>

                    <h4 class="title">
                        When is Big Data contained in a Data Mart or Data Warehouse?
                    </h4>
                    <p class="normal-text">
                        Data Marts contain data for one specific business purpose. These repositories are usually containers of summarized data ready to be analyzed for said business purpose.
                        <br><br>
                        Data Warehouses may contain various Data Marts, and aggregate this data
                        <table>
                            <tr class="title">
                                <th></th>
                                <th><h6>Data Mart</h6></th>
                                <th><h6>Data Warehouse</h6></th>
                            </tr>
                            <tr class="normal-text">
                                <td>Focus:</td>
                                <td>A single subject or functional organization area</td>
                                <td>Enterprise-wide repository of disparate data sources</td>
                            </tr>
                            <tr class="normal-text">
                                <td>Sources:</td>
                                <td>Relatively few sources linked to one line of business</td>
                                <td>Many external and internal sources from different areas of an organization</td>
                            </tr>
                            <tr class="normal-text">
                                <td>Size:</td>
                                <td>Less than 100 GB</td>
                                <td>100 GB minimum but often in the range of terabytes for large organizations *</td>
                            </tr>
                            <tr class="normal-text">
                                <td>Normalization:</td>
                                <td>No preference between a normalized and denormalized structure</td>
                                <td>Modern warehouses are mostly denormalized for quicker data querying and read performance</td>
                            </tr>
                            <tr class="normal-text">
                                <td>Decision Types:</td>
                                <td>Tactical decisions pertaining to particular business lines and ways of doing things</td>
                                <td>Strategic decisions that affect the entire enterprise</td>
                            </tr>
                            <tr class="normal-text">
                                <td>Cost:</td>
                                <td>Typically from $10,000 upwards</td>
                                <td>Varies but often greater than $100,000; for cloud solutions costs can be dramatically lower as organizations pay per use</td>
                            </tr>
                            <tr class="normal-text">
                                <td>Setup Time:</td>
                                <td>3-6 months</td>
                                <td>At least a year for on-premise warehouses; cloud data warehouses are much quicker to set up</td>
                            </tr>
                            <tr class="normal-text">
                                <td>Data Held:</td>
                                <td>Typically summarized data</td>
                                <td>Raw data, metadata, and summary data </td>
                            </tr>
                        </table>
                    </p>
                    
                    <p class="specialfont ">
                        *  Data is often measured in petabytes for mega-corporations, and is may be referred to as Data Lakes
                    </p>
            
                <a class="source" href="https://panoply.io/data-warehouse-guide/data-mart-vs-data-warehouse/">Table data obtained from Panoply website</a>
                <br><br>
                <figure>
                    <img class="centerimg " src="../../images/dataOrganization.jpg" alt="Model graphic given to help with capstone project for CIT327">
                    <figcaption class="source centered">Sample data organization model
                        <a href="https://panoply.io/data-warehouse-guide/data-mart-vs-data-warehouse/"> &nbsp;&nbsp;
                            [Image source]
                        </a>
                    </figcaption>
                </figure>
            </p>

        <h3 class="title">Data Models</h3>
            
            <p class="normal-text">
                Which model to use when: Inmon or Kimball?
            </p>

            <p class="normal-text">
                The Inmon Model (snowflake model) is best suited for the largest collections of data in Data Warehouses. They are not the fastest type of system to set up, they take many months of planning, setting up infrastructure, data collection, selecting the best tools to use to produce the results for the specific needs of the end users. This model takes advantage of horizontal scaling to handle the heavy burden of all the data spread across many nodes or computers.
                
                <br><br>
                <figure>
                    <img class="centerimg " src="../../images/inmon.png" alt="Graphic of Inmon Model">
                    <figcaption class="source centered">"Graphic of Inmon Model
                        <a href="https://piethein.medium.com/the-extinction-of-enterprise-data-warehousing-570b0034f47f"> &nbsp;&nbsp;
                            [Image source, accessed 7 April 2022]
                        </a>
                    </figcaption>
                </figure>
            </p>

            <p class="normal-text">
                The Kimball Model (star schema) works best for Data Marts with smaller data collections. They can be set up fairly quickly, and are must less costly, which helps smaller enterprises keep a lower budget. This model works well with vertical scaling.
                
                <br><br>
                <figure>
                    <img class="centerimg " src="../../images/kimball.png" alt="Kimball Model graphic">
                    <figcaption class="source centered">Kimball Model graphic
                        <a href="https://piethein.medium.com/the-extinction-of-enterprise-data-warehousing-570b0034f47f"> &nbsp;&nbsp;
                            [Image source, accessed 7 April 2022]
                        </a>
                    </figcaption>
                </figure>
            </p>

            <h3 class="title">Data Transformation</h3>

               <p class="normal-text">
                When designing a system for a Data Warehouse that needs to be spread out, tools like Cassandra, Hadoop and MapReduce will help significantly. They are created to support multiple programming languages for any custom query needs, and for horizontal scaling across many nodes. 
                
            </p>
             
             
            <h3 class="title">Data Analysis</h3>
              
                <p class="normal-text">
                    Once data sources are collected, they must be processed to draw out the insights hidden in the ocean of bits and bytes. Descriptive analytics is viewing past events' data. Diagnostic analytics finds out why the events may have happened. Predictive analytics are for viewing future events. Prescriptive analytics facilite future decisions based on these predictions.
              </p>
                <h4 class="title">Data Visualization</h4>
                <p class="normal-text">
                    Data vizualization will facilitate finding outliers, trends, cycles, anomalies and other points of interest for making the big business decisions. It is much more difficult to see patterns in tables of numbers that don't seem to make any sense, but having colors, lines, bars, circles, bubble and other visual aids make the patterns, or lack of patterns, pop out. Here a few samples of data visual aids:
                    <figure class="col2">
                        <div>
                            <h5 class="title">Bar Chart</h5>
                                <img src="../../images/barchart.png" alt="bar chart image" class="centered">
                        </div>
                        <div>
                            <h5 class="title">Pie Chart</h5>
                                <img src="../../images/piechart.png" alt="pie chart image" class="centered">
                        </div>
                        <div>
                            <h5 class="title">Pivot Table</h5>
                                <img src="../../images/pivot.png" alt="pivot table image" class="centered">
                        </div>
                        <div>
                            <h5 class="title">Box Plot Chart</h5>
                                <img src="../../images/boxplot.png" alt="boxplot image" class="centered">
                        </div>
                        <div>
                            <h5 class="title">Line Graph</h5>
                                <img src="../../images/linegraph.png" alt="line graph image" class="centered">
                        </div>
                        <div>
                            <h5 class="title">Area Chart</h5>
                                <img src="../../images/areachart.png" alt="area chart image" class="centered">
                        </div>
                        <figcaption class="source padleft8">
                            Images from     
                            <a href="https://careerfoundry.com/en/blog/data-analytics/data-visualization-types/">
                                Career Foundry online.
                            </a>
                        </figcaption>
                    </figure> <br><br>
                </p>

                    
            <h3 class="title">Managing Telemetry and Technical Debt</h3>

            <h4 class="title">Telemetry</h4>
                
                <p class="normal-text">
                    Constant and consistent measuring data flow, fluctuations, user engagement and feedback and many other values and monitoring charts and graphs based on this data is a whole other Big Data collection to worry about, but it helps maintain the necessary qualities of the Data Mart or Warehouse.
                </p>
                <p class="normal-text">
                    OpenTelemetry is a very popular, example of an integration tool, an open-source collection of APIs, supports many languages, including, but not limited to:<br><br>
                    • Java<br>
                    • C#<br>
                    • C++<br>
                    • JavaScript<br>
                    • Python<br>
                    • Rust<br>
                    • Erlang/Elixir<br><br>

                    OpenTelemetry also integrates with many common libraries and frameworks, including:<br><br>
                    • MySQL<br>
                    • Django<br>
                    • Redis<br>
                    • Kafka<br>
                    • Jetty<br>
                    • RabbitMQ<br>
                    • Akka<br>
                    • Spring<br>
                    • Flask<br>
                    • gorilla/mux<br>
                    • net/http<br>
                    • WSGI<br>
                    • JDBC<br>
                    • PostgreSQL<br>
                    OpenTelemetry also supports analysis of telemetric data from your system by their tools for easy extraction of valuable insigts.
                </p>



            <h4 class="title">Technical Debt</h4>
                <p class="normal-text">
                   Technical debt is the name given to previously unforeseen issues that cause extra financial and time costs, including salaries for developers and loss of respect from clients if the system is not available as contracted or there is downtime.
                </p>
                <p class="normal-text">
                      When it comes to software development, technical debt is the idea that certain necessary work gets delayed during the development of a software project in order to hit a deliverable or deadline.
      
                      "Technical debt is the coding you must do tomorrow because you took a shortcut in order to deliver the software today." <a class="source" href="https://www.bmc.com/blogs/technical-debt-explained-the-complete-guide-to-understanding-and-dealing-with-technical-debt">[Quote source]</a>
                </p>
                <p class="normal-text">
                    There are many reasons why technical debt exists:
                </p>
                <ul>
                    <li class="normal-text">
                        Poorly designed infrastructure
                    </li>
                    <li class="normal-text">
                        Deviation from business rules/principles
                    </li>
                    <li class="normal-text">
                        Poor or no design standards and patterns
                    </li>
                    <li class="normal-text">
                        Little or no testing
                    </li>
                    <li class="normal-text">
                        Constant or frequent variations of business rules and requirements or incoming data traffic patterns
                    </li>
                </ul>
                <p class="normal-text">
                    It is 
                </p>
                <p class="normal-text">

                </p>
                <p class="normal-text">
                    Integration of data collections with tools, frameworks and libraries to process them can have heavy technical debt. Using the MEAN stack with JavaScript developers on staff, this can be mitigated, as the MEAN stack is based on JavaScript and many tools support JavaScript.
                </p>
            

            <h3 class="title">Summary</h3>
                
                <p class="normal-text">
                    Explain what methods, tools, and techniques are best suited to deliver a manageable corporate data warehouse [or data mart?]

                    Define how would you go about selecting an analytical tool for the corporation; consider analytical programming but avoid where possible (due to high technical debt) when other tool sets can met needs effectively at low cost (like MicroStrategy, Tableau, Microsoft Power BI, etc.)

                    Planning is tantamount for any successful system. To select the correct tools, both financial and time costs must be taken into consideration. On-premise systems will have higher financial costs than cloud systems. Consisten telemetry measurements over time can be analyzed using the same methods to control technical debt and budget costs. Custom integrations should only be used if no other tools can provide the results needed for the business purpose(s).

                </p>
                <p class="normal-text">

                </p>

            <h3 class="title"></h3>
                <p class="normal-text">

                </p>
                <p class="normal-text">

                </p>

                <ul class="sources nodots">
                    Sources:
                    <li class="normal-text">
                        <a class="source" href="https://en.wikipedia.org/wiki/Big_data">
                             "Big Data", wikipedia.com, last edited 1 April 2022
                        </a>
                    </li>
                    <li class="normal-text">
                        <a href="https://www.infoworld.com/author/Scott-Carey/">
                            &nbsp;&nbsp;&nbsp;Carey, Scott
                        </a>,
                        <a class="source" href="https://www.infoworld.com/article/3639050/complexity-is-killing-software-developers.html">
                            "Complexity is killing software developers", InfoWorld, 1 November 2021
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://public.support.unisys.com/aseries/docs/clearpath-mcp-18.0/86000213-420/section-000019644.html">
                             "Enterprise Database Server Data and Structure Definition Language (DASDL) Programming Reference Manual - Embedded Structures", public.support.unisys.com Line 151
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://careerfoundry.com/en/blog/data-analytics/data-visualization-types">
                             Hiller, Will  "13 of the Most Common Types of Data Visualization", Career Foundry, 26 July 2021  line 180
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://towardsdatascience.com/understand-and-fight-technical-debts-in-your-data-warehouse-d455afed770e">
                             Lauer, Christian, "9 Technical Debts in your Data Warehouse - Reasons and how to solve them", Towards Data Science, 26 December 2020
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.precisely.com/blog/data-quality/5-characteristics-of-data-quality">
                             Levy Sarfin, Rachel, "5 Characteristics of Data Quality", precisely.com/blog, 7 May 2021 Line 217
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.sciencedirect.com/topics/computer-science/data-requirement-analysis">
                             Loshin, David "Data Requirement Analysis", Science Direct Line 173
                        </a>
                    </li>
                    <li class="normal-text">
                        <a id="bigdata" class="source" href="https://datasciencedegree.wisconsin.edu/data-science/what-is-big-data">
                             "What Is Big Data?", University of Wisconsin, Data Science  Line 156
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://careerfoundry.com/en/blog/data-analytics">
                             "What is data analytics?", Career Foundry
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.kentik.com/blog/how-to-maximize-the-value-of-streaming-telemetry-for-network-monitoring-and">
                             Kagawa, Aaron & Li, Crystal, "How to Maximize the Value of Streaming Telemetry for Network Monitoring and Analytics", kentik.com/blog, 28 August 2019
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.sei.cmu.edu/our-work/projects/display.cfm?customel_datapageid_4050=6520">
                             line 251
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.bmc.com/blogs/technical-debt-explained-the-complete-guide-to-understanding-and-dealing-with-technical-debt">
                            line 257
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.linkedin.com/pulse/unraveling-data-science-big-telemetry-join-mission-sandeep">
                             line 275
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.northeastern.edu/graduate/blog/data-analyst-skills">
                            line 282
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://gameanalytics.com/blog/maximizing-the-value-of-player-data/#telemetry-in-the-context-of-gaming">
                             line 289
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://www.softsuave.com/blog/mean-stack-vs-full-stack-developer-hire-for-your-next-project">
                             line 298
                        </a>
                    </li>
                    <li class="normal-text">E
                        <a class="source" href="https://www.stackstate.com/blog/the-ultimate-guide-to-telemetry">
                             line 331
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source" href="https://careerfoundry.com/en/blog/data-analytics/how-to-find-outliers">
                             line 338
                        </a>
                    </li>
                    <li class="normal-text">
                        <a class="source"
                        href="https://piethein.medium.com/the-extinction-of-enterprise-data-warehousing-570b0034f47f">
                            Strengholt, Piethein, "The Extinction of Enterprise Data Warehousing"
                        </a>
                    </li>
                </ul>
            </div>
        </main>
        <footer id="autofooter"></footer>
        <script src="../../js/main.js" type="module"></script>
    </body>
</html>
